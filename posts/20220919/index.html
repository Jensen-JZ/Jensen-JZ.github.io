<!DOCTYPE html>
<html lang=""><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>TorchScriptæ•™ç¨‹ï¼ˆè¯‘ï¼‰</title>
    <meta name="description" content="A simple homepage of Jensen Zhang.">
    <meta name="author" content='Jensen Zhang'>

    <link href="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/homepage_css2.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/buttonsstyle.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/backbutton.js"></script>
    <script async src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/busuanzi.pure.mini.js"></script>

    
    <script>
        WIDGET = {
        "CONFIG": {
            "modules": "0124",
            "background": "5",
            "tmpColor": "fff",
            "tmpSize": "16",
            "tmpPadding": "10px",
            "cityColor": "000",
            "citySize": "16",
            "aqiColor": "fff",
            "aqiSize": "16",
            "weatherIconSize": "24",
            "alertIconSize": "18",
            "padding": "0px",
            
            "language": "en",
            "key": "06a49925209149af84e325a6c7e5c521"
        }
        }
    </script>
    <script src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/qweather/he-simple-common-v2.0.2.js"></script>
    

    
    <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?a4cacad7bf6ee4f58534d26d5b23ad14";
          var s = document.getElementsByTagName("script")[0]; 
          s.parentNode.insertBefore(hm, s);
        })();
    </script>
    

    <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/search-v1.3.js"></script>

    
    <script id="search-result-template" type="text/x-js-template">
        <article id="summary-${key}">
            <header>
                <h3><i class="fas fa-file-alt"></i> <a href="${link}">${title}</a></h3>
                <h4>${date} | ${type} blog | ${tags}</h4>
            </header>
            <div>
                <div>${snippet}...</div>
                
                <div class="ReadButton">
                    <a class="read-more-link ReadButton_a" href="https://jen-jon.github.io/posts/20220919/">
                        <strong style="color: #fff;">Read More</strong>
                    </a>
                </div>
                
            </div>
            <hr>
        </article>
    </script>

    
    <link rel="stylesheet" href="/sass/researcher.min.css">

    
        <link rel="icon" type="image/ico" href="https://jen-jon.github.io/images/favicon.ico">
    

    
        
    
</head>

    <body><div id="ukraine" style="background-color: #1f71e0; ">
    <a class="cba fas fa-window-close" onclick="test()" style="display:block; float:right; width:30px; height:29px;" href="#"></a>
    <div style="height: 50px; display: flex; text-align: center; justify-content: center; align-items: center;">
        <div style="margin: 0 10px;">
            <div style="font-size: 45px;">ğŸ‡ºğŸ‡¦</div>
        </div>
        <div style="margin: 0 10px;">
            <a style="color: white;" href="/we-stand-with-ukraine">
                <div style="color: white; font-weight: bold; font-size: large;">We stand with Ukraine!</div>
                <div style="color: white; font-weight: bold; font-size: large;">æˆ‘ä»¬æ”¯æŒä¹Œå…‹å…°ï¼</div>
            </a>
        </div>
    </div>
</div>
<script>
    function test() {
        document.getElementById("ukraine").parentElement.removeChild(document.getElementById("ukraine"));
    }
</script>

<div class="container mt-5" style="text-align: right;">
    
    <div style="display: inline-flex; background-color: #1f71e0;">
        <div style="z-index: 9999;"><div id="he-plugin-simple"></div></div>
    </div>
    
    <nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0">
        <a class="navbar-brand mx-0 mr-sm-auto" href="https://jen-jon.github.io/" title="Jensen&#39;s Homepage">
          
          <i class="fas fa-home"></i>
          Jensen&#39;s Homepage
        </a>
        <div class="navbar-nav flex-row flex-wrap justify-content-center">
            
                
                
                    <a class="nav-item nav-link" href="/about" title="About">
                        About
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="/posts" title="Posts">
                        Posts
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="/mediatest" title="Media">
                        Media
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/Resumes/Resume_of_Jensen.pdf" title="Resume/CV">
                        Resume/CV
                    </a>
                    
                
            
        </div>
    </nav>
</div>
<hr><div id="content">
<div class="container">
    
    <h1 style="color: #1f71e0;">TorchScriptæ•™ç¨‹ï¼ˆè¯‘ï¼‰</h1>
    
    <h5><a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#tracing-modules">Reposted</a> by <a href="https://jen-jon.github.io/">Jensen Zhang</a> on <em>September 19, 2022</em> | <spa id="busuanzi_container_page_pv"><i class="fas fa-eye"></i> <em><span id="busuanzi_value_page_pv"></span></em> readings</span> </h5>
    
    <h5>This article is about <em style="color: #1f71e0;">3517</em> words and may take <em style="color: #1f71e0;">8</em> minutes to read.</h5>
    <hr>
    
    
    <p><img src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/blogstatic/20220919/title.png" alt="Logo"/></p>
    <hr>
    
    
    <blockquote>
        <p><strong>Type: technology blog</strong></p>
        <p><strong>Tags: PyTorchï¼›JIT</strong></p>
    </blockquote>
    <hr>
    
    
    <h1 style="color: #1f71e0;">Content</h1>
    <br>
    
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>__version__
</span></span></code></pre></div><pre><code>'1.8.2'
</code></pre>
<h2 id="ç¼–å†™pytorchæ¨¡å‹çš„åŸºæœ¬çŸ¥è¯†">ç¼–å†™PyTorchæ¨¡å‹çš„åŸºæœ¬çŸ¥è¯†</h2>
<p>æˆ‘ä»¬é¦–å…ˆæ¥å®šä¹‰ä¸€ä¸ªç®€å•çš„<code>Module</code>ã€‚<code>Module</code>æ˜¯PyTorchæ¨¡å‹çš„åŸºæœ¬ç»„æˆå•ä½ã€‚å…¶ä¸­åŒ…å«ï¼š</p>
<ul>
<li>
<p>ä¸€ä¸ªæ„é€ å‡½æ•°ï¼Œä¸ºæ¨¡å—çš„è°ƒç”¨ä½œå‡†å¤‡ï¼›</p>
</li>
<li>
<p>ä¸€ç»„å‚æ•°å’Œå­æ¨¡å—ï¼Œå®ƒä»¬ç”±æ„é€ å‡½æ•°åˆå§‹åŒ–ï¼Œå¹¶å¯ç”±æ¨¡å—åœ¨è°ƒç”¨æœŸé—´ä½¿ç”¨ï¼›</p>
</li>
<li>
<p>ä¸€ä¸ª<code>forward</code>å‡½æ•°ï¼Œè¿™æ˜¯åœ¨è°ƒç”¨æ¨¡å—æ—¶è¿è¡Œçš„ä»£ç ã€‚</p>
</li>
</ul>
<p>æ¥çœ‹çœ‹ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(x <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>print(my_cell(x, h))
</span></span></code></pre></div><pre><code>(tensor([[0.5848, 0.6401, 0.5124, 0.6093],
        [0.2706, 0.4608, 0.9002, 0.7638],
        [0.9597, 0.7959, 0.6197, 0.6299]]), tensor([[0.5848, 0.6401, 0.5124, 0.6093],
        [0.2706, 0.4608, 0.9002, 0.7638],
        [0.9597, 0.7959, 0.6197, 0.6299]]))
</code></pre>
<p>ä»ä¸Šé¢ä»£ç ä¸­å¯ä»¥å‘ç°ï¼Œ</p>
<ul>
<li>
<p>åˆ›å»ºäº†ä¸€ä¸ª<code>torch.nn.Module</code>çš„å­ç±»ï¼›</p>
</li>
<li>
<p>å®šä¹‰äº†ä¸€ä¸ªæ„é€ å‡½æ•°ï¼Œå¹¶ä¸”æ²¡æœ‰åšä»»ä½•åŠ¨ä½œé™¤äº†è°ƒç”¨çˆ¶ç±»<code>super</code>çš„æ„é€ å‡½æ•°ï¼›</p>
</li>
<li>
<p>å®šä¹‰äº†ä¸€ä¸ª<code>forward</code>å‡½æ•°ï¼Œæ¥æ”¶ä¸¤ä¸ªè¾“å…¥å¹¶è¿”å›ä¸¤ä¸ªè¾“å‡ºï¼›<code>forward</code>å‡½æ•°ä¸­çš„å®é™…å†…å®¹å¹¶ä¸é‡è¦ï¼Œç±»ä¼¼äºä¸€ç§å‡çš„RNNå•å…ƒï¼Œæ˜¯ä¸€ä¸ªåº”ç”¨åœ¨å¾ªç¯ä¸­çš„å‡½æ•°ã€‚</p>
</li>
</ul>
<p>æœ€åï¼Œå°†è¯¥ç±»å®ä¾‹åŒ–ï¼Œå¹¶åˆ›å»º<code>x</code>å’Œ<code>h</code>ï¼Œå®ƒä»¬æ˜¯3x4çš„éšæœºçŸ©é˜µã€‚ç„¶åé€šè¿‡<code>my_cell(x, h)</code>è°ƒç”¨è¯¥å®ä¾‹ï¼ŒåŒæ ·è¿™ä¹Ÿè°ƒç”¨äº†<code>forward</code>å‡½æ•°ã€‚</p>
<p>æ¥ä¸‹æ¥åšç‚¹æ›´æœ‰è¶£çš„ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>linear(x) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>print(my_cell)
</span></span><span style="display:flex;"><span>print(my_cell(x, h))
</span></span></code></pre></div><pre><code>MyCell(
  (linear): Linear(in_features=4, out_features=4, bias=True)
)
(tensor([[-0.0131,  0.2256,  0.5951,  0.4361],
        [ 0.0035,  0.7586,  0.6020,  0.0687],
        [ 0.6873,  0.3057,  0.7030,  0.3927]], grad_fn=&lt;TanhBackward&gt;), tensor([[-0.0131,  0.2256,  0.5951,  0.4361],
        [ 0.0035,  0.7586,  0.6020,  0.0687],
        [ 0.6873,  0.3057,  0.7030,  0.3927]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<p>æˆ‘ä»¬é‡æ–°å®šä¹‰äº†<code>MyCell</code>æ¨¡å—ï¼Œä½†åœ¨å…¶ä¸­æ·»åŠ äº†<code>self.linear</code>å±æ€§ï¼Œå¹¶åœ¨<code>forward</code>å‡½æ•°ä¸­è°ƒç”¨äº†<code>self.linear</code>ã€‚</p>
<p>è¿™é‡Œç©¶ç«Ÿå‘ç”Ÿä»€ä¹ˆäº†å‘¢ï¼Ÿ<code>torch.nn.Linear</code>æ˜¯PyTorchæ ‡å‡†åº“ä¸­çš„<code>Module</code>ã€‚æ­£å¦‚åŒ<code>MyCell</code>ï¼Œå¯ä»¥ä½¿ç”¨è°ƒç”¨è¯­æ³•æ¥è°ƒç”¨å®ƒã€‚æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªç”±<code>Module</code>sç»„æˆçš„å±‚æ¬¡ç»“æ„ã€‚</p>
<p><code>Module</code>ä¸­çš„<code>print</code>ä¼šæ‰“å°å‡º<code>Module</code>çš„å­ç±»å±‚æ¬¡ç»“æ„çš„ç›´è§‚è¡¨ç¤ºã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œå¯ä»¥çœ‹åˆ°<code>Linear</code>å­ç±»ä»¥åŠå…¶å‚æ•°ã€‚</p>
<p>é€šè¿‡è¿™ç§æ–¹å¼ç»„åˆæ¨¡å—ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç®€æ´å’Œé«˜å¯è¯»åœ°ä½¿ç”¨å¯é‡ç”¨ç»„ä»¶æ¥ç¼–å†™æ¨¡å‹ã€‚</p>
<p>ä½ å¯èƒ½ä¼šæ³¨æ„åˆ°è¾“å‡ºç»“æœä¸­çš„<code>grad_fn</code>ï¼Œè¿™æ˜¯PyTorchè‡ªåŠ¨å¾®åˆ†çš„ä¸€ä¸ªç»†èŠ‚ï¼Œç§°ä¹‹ä¸º<a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"><code>autograd</code></a>ã€‚ç®€è€Œè¨€ä¹‹ï¼Œè¿™å¥—ç³»ç»Ÿå…è®¸æˆ‘ä»¬é€šè¿‡æ½œåœ¨çš„å¤æ‚ç¨‹åºæ¥è®¡ç®—å¯¼æ•°ã€‚è¿™ç§è®¾è®¡å¢åŠ äº†æ¨¡å‹ç¼–å†™æ–¹é¢çš„çµæ´»æ€§ã€‚</p>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬æ¥ç ”ç©¶ä¸€ä¸‹æ‰€è°“çš„çµæ´»æ€§ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyDecisionGate</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> x<span style="color:#f92672">.</span>sum() <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>             <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span>x
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dg <span style="color:#f92672">=</span> MyDecisionGate()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>dg(self<span style="color:#f92672">.</span>linear(x)) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>print(my_cell)
</span></span><span style="display:flex;"><span>print(my_cell(x, h))
</span></span></code></pre></div><pre><code>MyCell(
  (dg): MyDecisionGate()
  (linear): Linear(in_features=4, out_features=4, bias=True)
)
(tensor([[ 0.4873, -0.0183,  0.5451,  0.6425],
        [ 0.1686,  0.3009,  0.6721,  0.3504],
        [ 0.9206,  0.2258,  0.6589,  0.5597]], grad_fn=&lt;TanhBackward&gt;), tensor([[ 0.4873, -0.0183,  0.5451,  0.6425],
        [ 0.1686,  0.3009,  0.6721,  0.3504],
        [ 0.9206,  0.2258,  0.6589,  0.5597]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<p>æˆ‘ä»¬å†ä¸€æ¬¡é‡æ–°å®šä¹‰äº†<code>MyCell</code>ç±»ï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº†<code>MyDecisionGate</code>ã€‚è¿™ä¸ªæ¨¡å—ç”¨æ¥<strong>æ§åˆ¶æµ</strong>ã€‚æ§åˆ¶æµç”±å¾ªç¯å’Œ<code>if</code>è¯­å¥ç­‰å†…å®¹ç»„æˆã€‚</p>
<p>è®¸å¤šæ¡†æ¶é‡‡ç”¨äº†è®¡ç®—ç¬¦å·å¯¼æ•°çš„æ–¹æ³•ï¼Œå¹¶ä¸”ç»™å®šå®Œæ•´çš„ç¨‹åºè¡¨ç¤ºã€‚ä½†åœ¨PyTorchä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨â€œæ¢¯åº¦èƒ¶å¸¦â€ã€‚æˆ‘ä»¬åœ¨æ“ä½œå‘ç”Ÿæ—¶è®°å½•å®ƒä»¬ï¼Œå¹¶åœ¨è®¡ç®—å¯¼æ•°å›æ”¾å®ƒä»¬ã€‚è¿™æ ·å°±ä¸å¿…æ˜¾å¼åœ°ä¸ºè¯­è¨€ä¸­çš„æ‰€æœ‰æ„é€ å®šä¹‰å¯¼æ•°ã€‚</p>
<p><img src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/blogstatic/20220919/dynamic_graph.gif" alt="How autograd works"></p>
<h2 id="torchscriptåŸºç¡€">TorchScriptåŸºç¡€</h2>
<p>ç°åœ¨ä»¥æˆ‘ä»¬ä¸Šè¿°ç¤ºä¾‹ä¸ºä¾‹ï¼Œçœ‹çœ‹å¦‚ä½•ä½¿ç”¨<code>TorchScript</code>ã€‚</p>
<p>ç®€è€Œè¨€ä¹‹ï¼Œ<code>TorchScript</code>æä¾›äº†ä¸€äº›å·¥å…·æ¥æ•è·æ¨¡å‹çš„å®šä¹‰ï¼Œç”šè‡³è€ƒè™‘åˆ°äº†PyTorchçš„çµæ´»æ€§å’ŒåŠ¨æ€æ€§ã€‚è®©æˆ‘ä»¬ä»è¢«ç§°ä¸º<em>tracing</em>çš„å·¥å…·æ¥å¼€å§‹æ¢ç©¶ã€‚</p>
<h3 id="tracing-modules">Tracing <code>Modules</code></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>linear(x) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>x, h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>), torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>traced_cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(my_cell, (x, h))
</span></span><span style="display:flex;"><span>print(traced_cell)
</span></span><span style="display:flex;"><span>traced_cell(x, h)
</span></span></code></pre></div><pre><code>MyCell(
  original_name=MyCell
  (linear): Linear(original_name=Linear)
)





(tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
         [-0.1340,  0.6531,  0.3963,  0.8801],
         [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;),
 tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
         [-0.1340,  0.6531,  0.3963,  0.8801],
         [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<p>æˆ‘ä»¬ç¨å¾®å¾€å‰å›æº¯äº†ä¸€ç‚¹ï¼Œé‡‡ç”¨<code>MyCell</code>ç±»çš„ç¬¬äºŒä¸ªç‰ˆæœ¬ã€‚å’Œä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å®ä¾‹åŒ–äº†å®ƒï¼Œä½†è¿™ä¸€æ¬¡æˆ‘ä»¬è°ƒç”¨äº†<code>torch.jit.trace</code>ï¼Œå¹¶å°†å®ä¾‹åŒ–çš„<code>Module</code>ä¼ å…¥ï¼Œå¹¶ä¼ å…¥ç½‘ç»œä¸­çš„ç¤ºä¾‹è¾“å…¥ã€‚</p>
<p>è¿™ä¸ªè¿‡ç¨‹ä¸­åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿå®ƒè°ƒç”¨äº†å®ä¾‹åŒ–<code>Module</code>ï¼Œè®°å½•äº†<code>Module</code>è¿è¡Œæ—¶å‘ç”Ÿçš„æ“ä½œï¼Œå¹¶åˆ›å»ºäº†<code>torch.jit.ScriptModule</code>çš„å®ä¾‹ï¼ˆ<code>TracedModule</code>ä¾¿æ˜¯å…¶å®ä¾‹ï¼‰ã€‚</p>
<p>TorchScriptå°†å…¶å®šä¹‰è®°å½•åœ¨ä¸­é—´è¡¨ç¤ºï¼ˆIntermediate Representationï¼‰ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­é€šå¸¸è¢«ç§°ä¸º<code>graph</code>ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨<code>.graph</code>å±æ€§æ£€æŸ¥è¯¥graphï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>graph)
</span></span></code></pre></div><pre><code>graph(%self.1 : __torch__.MyCell,
      %input : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),
      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):
  %21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=&quot;linear&quot;](%self.1)
  %23 : Tensor = prim::CallMethod[name=&quot;forward&quot;](%21, %input)
  %14 : int = prim::Constant[value=1]() # /tmp/ipykernel_18098/4265555285.py:7:0
  %15 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%23, %h, %14) # /tmp/ipykernel_18098/4265555285.py:7:0
  %16 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%15) # /tmp/ipykernel_18098/4265555285.py:7:0
  %17 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%16, %16)
  return (%17)
</code></pre>
<p>ç„¶è€Œï¼Œè¿™æ˜¯ä¸€ç§éå¸¸<code>low-level</code>çš„è¡¨ç¤ºï¼Œå›¾è¡¨ä¸­åŒ…å«çš„å¤§å¤šæ•°ä¿¡æ¯å¯¹æœ€ç»ˆç”¨æˆ·éƒ½æ²¡æœ‰ç”¨å¤„ã€‚å–è€Œä»£ä¹‹çš„æ˜¯ï¼Œå¯ä»¥ä½¿ç”¨<code>.code</code>å±æ€§æ¥æä¾›ä»£ç çš„Pythonè¯­æ³•è§£é‡Šï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = torch.add((self.linear).forward(input, ), h, alpha=1)
  _1 = torch.tanh(_0)
  return (_1, _1)
</code></pre>
<p>ä¸ºä»€ä¹ˆè¦è¿™æ ·åšå‘¢ï¼Ÿä¸»è¦æœ‰ä»¥ä¸‹å‡ ä¸ªåŸå› ï¼š</p>
<ul>
<li>
<p>TorchScriptä»£ç å¯ä»¥åœ¨å…¶è‡ªå·±çš„è§£é‡Šå™¨ä¸­è°ƒç”¨ï¼Œè¯¥è§£é‡Šå™¨åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªå—é™çš„Pythonè§£é‡Šå™¨ã€‚æ­¤è§£é‡Šå™¨ä¸è·å–å…¨å±€è§£é‡Šå™¨é”ï¼Œå› æ­¤å¯ä»¥åœ¨åŒä¸€å®ä¾‹ä¸ŠåŒæ—¶å¤„ç†è®¸å¤šè¯·æ±‚ã€‚</p>
</li>
<li>
<p>æ­¤æ ¼å¼å…è®¸æˆ‘ä»¬å°†æ•´ä¸ªæ¨¡å‹ä¿å­˜åˆ°ç£ç›˜ï¼Œå¹¶å°†å…¶åŠ è½½åˆ°å¦ä¸€ä¸ªç¯å¢ƒä¸­ï¼Œä¾‹å¦‚åœ¨ç”¨éPythonè¯­è¨€ç¼–å†™çš„æœåŠ¡å™¨ä¸­ã€‚</p>
</li>
<li>
<p>TorchScriptä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§è¡¨ç¤ºå½¢å¼ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å…¶ä¸­å¯¹ä»£ç è¿›è¡Œç¼–è¯‘å™¨ä¼˜åŒ–ï¼Œä»¥æä¾›æ›´é«˜æ•ˆçš„æ‰§è¡Œã€‚</p>
</li>
<li>
<p>TorchScriptå…è®¸æˆ‘ä»¬ä¸è®¸å¤šåç«¯/è®¾å¤‡è¿è¡Œæ—¶äº¤äº’ï¼Œè¿™äº›åç«¯/è®¾å¤‡è¿è¡Œæ—¶éœ€è¦æ¯”å•ä¸ªè¿ç®—ç¬¦æ›´å¹¿æ³›çš„ç¨‹åºè§†å›¾ã€‚</p>
</li>
</ul>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè°ƒç”¨<code>traced_cell</code>ä¼šäº§ç”Ÿä¸Pythonæ¨¡å—ç›¸åŒçš„ç»“æœï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(my_cell(x, h))
</span></span><span style="display:flex;"><span>print(traced_cell(x, h))
</span></span></code></pre></div><pre><code>(tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;), tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;))
(tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;), tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<h3 id="using-scripting-to-convert-modules">Using Scripting to Convert Modules</h3>
<p>ä¸Šè¿°ç¤ºä¾‹æˆ‘ä»¬ä½¿ç”¨<code>MyCell</code>çš„ç¬¬äºŒä¸ªç‰ˆæœ¬è€Œä¸æ˜¯å¸¦æœ‰æ§åˆ¶æµåŠ è½½å­æ¨¡å—çš„ç‰ˆæœ¬æ˜¯æœ‰åŸå› çš„ï¼Œç°åœ¨æˆ‘ä»¬æ¥æ¢ç©¶ä¸€ä¸‹ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyDecisionGate</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> x<span style="color:#f92672">.</span>sum() <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span>x
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, dg):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dg <span style="color:#f92672">=</span> dg
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>dg(self<span style="color:#f92672">.</span>linear(x)) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell(MyDecisionGate())
</span></span><span style="display:flex;"><span>traced_cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(my_cell, (x, h))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>dg<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    argument_1: Tensor) -&gt; Tensor:
  return torch.neg(argument_1)

def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(input, ), )
  _1 = torch.tanh(torch.add(_0, h, alpha=1))
  return (_1, _1)



/home/jensen/.conda/envs/venv_torch/lib/python3.7/site-packages/ipykernel_launcher.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  This is separate from the ipykernel package so we can avoid doing imports until
</code></pre>
<p>æŸ¥çœ‹<code>.code</code>çš„è¾“å‡ºï¼Œå¯ä»¥å‘ç°å®Œå…¨æ‰¾ä¸åˆ°<code>if-else</code>çš„è¸ªè¿¹ï¼WHY?! Tracingæ‰€åšçš„æ­£å¦‚æˆ‘ä»¬æ‰€è¯´çš„é‚£æ ·ï¼Œè¿è¡Œä»£ç ï¼Œè®°å½•æ‰€å‘ç”Ÿçš„æ“ä½œï¼Œå¹¶æ„é€ ä¸€ä¸ªæ‰§è¡Œè¿™äº›æ“ä½œçš„<code>ScriptModule</code>ã€‚ä¸å¹¸çš„æ˜¯ï¼Œåƒæ§åˆ¶æµè¿™æ ·çš„æ“ä½œè¢«æ“¦é™¤äº†ã€‚</p>
<p>é‚£å¦‚ä½•åœ¨TorchScriptä¸­å‡†ç¡®åœ°è¡¨ç¤ºè¿™ä¸ªæ¨¡å—ï¼Ÿæˆ‘ä»¬æä¾›äº†ä¸€ä¸ª<strong>script compiler</strong>ï¼Œå®ƒå¯ä»¥ç›´æ¥åˆ†æPythonæºä»£ç ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºTorchScriptã€‚è®©æˆ‘ä»¬ç›´æ¥ä½¿ç”¨<strong>script compiler</strong>è½¬æ¢<code>MyDecisionGate</code>ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scripted_gate <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(MyDecisionGate())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell(scripted_gate)
</span></span><span style="display:flex;"><span>scripted_cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(my_cell)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(scripted_gate<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(scripted_cell<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    x: Tensor) -&gt; Tensor:
  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))
  if _0:
    _1 = x
  else:
    _1 = torch.neg(x)
  return _1

def forward(self,
    x: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(x, ), )
  new_h = torch.tanh(torch.add(_0, h, alpha=1))
  return (new_h, new_h)
</code></pre>
<p>å¤ªæ£’äº†ï¼æˆ‘ä»¬ç°åœ¨å·²ç»å‡†ç¡®åœ°æ•è·äº†æˆ‘ä»¬çš„ç¨‹åºåœ¨TorchScriptä¸­çš„è¡Œä¸ºã€‚ç°åœ¨è®©æˆ‘ä»¬å°è¯•è¿è¡Œè¯¥ç¨‹åºï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># New inputs</span>
</span></span><span style="display:flex;"><span>x, h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>), torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>scripted_cell(x, h)
</span></span></code></pre></div><pre><code>(tensor([[0.7933, 0.2852, 0.3526, 0.0098],
         [0.7790, 0.6442, 0.5631, 0.6060],
         [0.4623, 0.2208, 0.0442, 0.8844]], grad_fn=&lt;TanhBackward&gt;),
 tensor([[0.7933, 0.2852, 0.3526, 0.0098],
         [0.7790, 0.6442, 0.5631, 0.6060],
         [0.4623, 0.2208, 0.0442, 0.8844]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<h3 id="æ··åˆscriptingå’Œtracing">æ··åˆScriptingå’ŒTracing</h3>
<p>æœ‰äº›æƒ…å†µä¸‹éœ€è¦ä½¿ç”¨tracingè€Œä¸æ˜¯scriptingï¼ˆä¾‹å¦‚ï¼Œæ¨¡å—ä¸­å«æœ‰è®¸å¤šæ¶æ„å†³ç­–ï¼Œè¿™äº›å†³ç­–æ˜¯åŸºäºæˆ‘ä»¬ä¸å¸Œæœ›å‡ºç°åœ¨TorchScriptä¸­å¸¸é‡Pythonå€¼åšå‡ºçš„ï¼‰ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥å°†scriptingå’Œtracingç»“åˆèµ·æ¥ä½¿ç”¨ï¼š<code>torch.jit.script</code>å°†ä¼šå†…è”ä¸€ä¸ª<code>traced</code>æ¨¡å—ï¼Œtracingå°†ä¼šå†…è”ä¸€ä¸ª<code>scripted</code>æ¨¡å—ã€‚</p>
<p>ç¬¬ä¸€ç§æƒ…å†µçš„ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyRNNLoop</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyRNNLoop, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(MyCell(scripted_gate), (x, h))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, xs):
</span></span><span style="display:flex;"><span>        h, y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>), torch<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(xs<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)):
</span></span><span style="display:flex;"><span>            y, h <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>cell(xs[i], h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> y, h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>run_loop <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(MyRNNLoop())
</span></span><span style="display:flex;"><span>print(run_loop<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(run_loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(run_loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>dg<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    xs: Tensor) -&gt; Tuple[Tensor, Tensor]:
  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y0 = y
  h0 = h
  for i in range(torch.size(xs, 0)):
    _0 = (self.cell).forward(torch.select(xs, 0, i), h0, )
    y1, h1, = _0
    y0, h0 = y1, h1
  return (y0, h0)

def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(input, ), )
  _1 = torch.tanh(torch.add(_0, h, alpha=1))
  return (_1, _1)

def forward(self,
    x: Tensor) -&gt; Tensor:
  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))
  if _0:
    _1 = x
  else:
    _1 = torch.neg(x)
  return _1
</code></pre>
<p>ç¬¬äºŒç§æƒ…å†µçš„ä¾‹å­ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WrapRNN</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(WrapRNN, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>loop <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(MyRNNLoop())
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, xs):
</span></span><span style="display:flex;"><span>        y, h <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>loop(xs)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>relu(y)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>traced <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(WrapRNN(), (torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)))
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>loop<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>dg<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    argument_1: Tensor) -&gt; Tensor:
  _0, y, = (self.loop).forward(argument_1, )
  return torch.relu(y)

def forward(self,
    xs: Tensor) -&gt; Tuple[Tensor, Tensor]:
  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y0 = y
  h0 = h
  for i in range(torch.size(xs, 0)):
    _0 = (self.cell).forward(torch.select(xs, 0, i), h0, )
    y1, h1, = _0
    y0, h0 = y1, h1
  return (y0, h0)

def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(input, ), )
  _1 = torch.tanh(torch.add(_0, h, alpha=1))
  return (_1, _1)

def forward(self,
    x: Tensor) -&gt; Tensor:
  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))
  if _0:
    _1 = x
  else:
    _1 = torch.neg(x)
  return _1
</code></pre>
<p>å› è€Œï¼Œscriptingå’Œtracingå¯ä»¥åœ¨æƒ…å†µéœ€è¦æ—¶å°†å®ƒä»¬åˆå¹¶åœ¨ä¸€èµ·ä½¿ç”¨ã€‚</p>
<h3 id="ä¿å­˜å’ŒåŠ è½½æ¨¡å‹">ä¿å­˜å’ŒåŠ è½½æ¨¡å‹</h3>
<p>æˆ‘ä»¬æä¾›äº†ä»¥å­˜æ¡£æ ¼å¼å°†TorchScriptæ¨¡å—ä¿å­˜å’ŒåŠ è½½åˆ°ç£ç›˜æˆ–ä»ç£ç›˜åŠ è½½çš„APIsã€‚è¿™ç§æ ¼å¼åŒ…å«ä»£ç ã€å‚æ•°ã€å±æ€§å’Œè°ƒè¯•ä¿¡æ¯ï¼Œè¿™æ„å‘³ç€å­˜æ¡£æ˜¯æ¨¡å‹çš„ç‹¬ç«‹è¡¨ç¤ºå½¢å¼ï¼Œå¯ä»¥åœ¨å®Œå…¨ç‹¬ç«‹çš„è¿›ç¨‹ä¸­åŠ è½½ã€‚</p>
<p>æ¥ä¸‹æ¥è®©æˆ‘ä»¬ä¿å­˜å¹¶åŠ è½½wrapped RNNæ¨¡å—ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>traced<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;wrapped_rnn.pt&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>loaded <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;wrapped_rnn.pt&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(loaded)
</span></span><span style="display:flex;"><span>print(loaded<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>RecursiveScriptModule(
  original_name=WrapRNN
  (loop): RecursiveScriptModule(
    original_name=MyRNNLoop
    (cell): RecursiveScriptModule(
      original_name=MyCell
      (dg): RecursiveScriptModule(original_name=MyDecisionGate)
      (linear): RecursiveScriptModule(original_name=Linear)
    )
  )
)
def forward(self,
    argument_1: Tensor) -&gt; Tensor:
  _0, y, = (self.loop).forward(argument_1, )
  return torch.relu(y)
</code></pre>
<p>å¦‚æ‚¨æ‰€è§ï¼Œåºåˆ—åŒ–ä¿ç•™äº†æ¨¡å—å±‚æ¬¡ç»“æ„å’Œæˆ‘ä»¬ä¸€ç›´åœ¨ç ”ç©¶çš„ä»£ç ã€‚ä¾‹å¦‚ï¼Œä¹Ÿå¯ä»¥å°†æ¨¡å‹<a href="https://pytorch.org/tutorials/advanced/cpp_export.html">åŠ è½½åˆ°C++</a>ä¸­ï¼Œä»¥ä¾¿åœ¨ä¸ä½¿ç”¨Pythonçš„æƒ…å†µä¸‹æ‰§è¡Œã€‚</p>
<h2 id="å»¶ä¼¸é˜…è¯»">å»¶ä¼¸é˜…è¯»</h2>
<p>æˆ‘ä»¬å·²ç»å®Œæˆäº†æœ¬æ•™ç¨‹ï¼æœ‰å…³æ›´å¤æ‚çš„æ¼”ç¤ºï¼Œè¯·æŸ¥çœ‹ä½¿ç”¨TorchScriptè½¬æ¢æœºå™¨ç¿»è¯‘æ¨¡å‹NeurIPSçš„æ¼”ç¤ºï¼š</p>
<p><a href="https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ">https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ</a></p>

    <div class="CornerButtons">
        <div class="CornerAnimayedFlex">
            <div class="CornerButton" title="Back to the top">
                <a href="#top" class="cba fas fa-hand-middle-finger" ></a>
            </div>
        </div>
    </div>

<hr>

<h1 style="color: #1f71e0;">Comments</h1>
<script defer src="https://utteranc.es/client.js" 
repo="Jen-Jon/Jen-Jon.github.io" 
issue-term="title" 
theme="github-light" 
crossorigin="anonymous" async></script>


</div>

<h5 style="text-align: center; font-size: large;">This blog is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0</a>, please indicate the source for non-commercial reposted.</h5>


        </div><strong id="footer" class="mb-5">
    <hr>
    
    <div class="container text-center">
        
            <a href="https://github.com/Jen-Jon/" class="fab fa-github fa-1x" title="Github" style="text-decoration: none;"></a>
        
            <a href="https://hub.docker.com/u/ijerry22" class="fab fa-docker fa-1x" title="DockerHub" style="text-decoration: none;"></a>
        
            <a href="https://www.researchgate.net/profile/Jingyao-Zhang-4" class="fab fa-researchgate fa-1x" title="researchgate" style="text-decoration: none;"></a>
        
            <a href="mailto:jensen.acm@gmail.com" class="fas fa-envelope fa-1x" title="E-mail" style="text-decoration: none;"></a>
        
    </div>
    
        <div class="container text-center">
            <h5 class="text-center" style="font-size: small;">Copyright Â© 2020-2024 <a href="https://github.com/Jen-Jon/" style="color: #1f71e0;" title="Jensen-Jon">Jensen-Jon</a>. All rights reserved.</h5>
        </div>
    
</div>
</body>
</html>
